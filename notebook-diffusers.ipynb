{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5dc696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T16:38:48.502481Z",
     "iopub.status.busy": "2023-03-25T16:38:48.501981Z",
     "iopub.status.idle": "2023-03-25T16:39:02.673090Z",
     "shell.execute_reply": "2023-03-25T16:39:02.671933Z"
    },
    "papermill": {
     "duration": 14.178744,
     "end_time": "2023-03-25T16:39:02.676193",
     "exception": false,
     "start_time": "2023-03-25T16:38:48.497449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime==1.10.0\r\n",
      "  Downloading onnxruntime-1.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from onnxruntime==1.10.0) (3.19.4)\r\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.7/site-packages (from onnxruntime==1.10.0) (1.12)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from onnxruntime==1.10.0) (1.21.6)\r\n",
      "Installing collected packages: onnxruntime\r\n",
      "Successfully installed onnxruntime-1.10.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime-training==1.10.0 (from versions: 1.7.0, 1.8.0, 1.8.1, 1.9.0, 1.11.0, 1.11.1, 1.12.0, 1.13.1, 1.14.0, 1.14.1)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for onnxruntime-training==1.10.0\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime==1.10.0\n",
    "!pip install onnxruntime-training==1.10.0\n",
    "#!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811c35ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T16:39:02.683099Z",
     "iopub.status.busy": "2023-03-25T16:39:02.682776Z",
     "iopub.status.idle": "2023-03-25T16:39:31.715449Z",
     "shell.execute_reply": "2023-03-25T16:39:31.714096Z"
    },
    "papermill": {
     "duration": 29.038975,
     "end_time": "2023-03-25T16:39:31.718109",
     "exception": false,
     "start_time": "2023-03-25T16:39:02.679134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\r\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.7/site-packages (0.12.0)\r\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.7/site-packages (0.12.21)\r\n",
      "Collecting open-clip-torch\r\n",
      "  Downloading open_clip_torch-2.16.0-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2023.1.0)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.10.1)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.6)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.0)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.1)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.2.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (23.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.14)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate) (6.0)\r\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from accelerate) (1.11.0)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from accelerate) (5.9.1)\r\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (8.1.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.14.0)\r\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.0.11)\r\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.1.27)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (1.15.0)\r\n",
      "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (3.19.4)\r\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.7/site-packages (from wandb) (2.3)\r\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.7/site-packages (from wandb) (0.1.2)\r\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.7/site-packages (from wandb) (1.3.2)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from wandb) (59.8.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from open-clip-torch) (0.12.0)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from open-clip-torch) (2021.11.10)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from open-clip-torch) (0.1.97)\r\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.7/site-packages (from open-clip-torch) (0.6.12)\r\n",
      "Collecting ftfy\r\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\r\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.1.1)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.14)\r\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from ftfy->open-clip-torch) (0.2.5)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.8.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->open-clip-torch) (9.1.1)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.5)\r\n",
      "Installing collected packages: ftfy, open-clip-torch\r\n",
      "Successfully installed ftfy-6.1.1 open-clip-torch-2.16.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting diffusers\r\n",
      "  Downloading diffusers-0.14.0-py3-none-any.whl (737 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.4/737.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (1.7.3)\r\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from diffusers) (2021.11.10)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from diffusers) (2.28.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from diffusers) (6.0.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from diffusers) (3.7.1)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from diffusers) (9.1.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from diffusers) (0.10.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from diffusers) (1.21.6)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
      "Collecting huggingface-hub>=0.10.0\r\n",
      "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.10.0->diffusers) (4.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->diffusers) (3.8.0)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (2.1.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (1.26.14)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (2022.12.7)\r\n",
      "Installing collected packages: huggingface-hub, transformers, diffusers\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.10.1\r\n",
      "    Uninstalling huggingface-hub-0.10.1:\r\n",
      "      Successfully uninstalled huggingface-hub-0.10.1\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.20.1\r\n",
      "    Uninstalling transformers-4.20.1:\r\n",
      "      Successfully uninstalled transformers-4.20.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cached-path 1.1.6 requires huggingface-hub<0.11.0,>=0.8.1, but you have huggingface-hub 0.13.3 which is incompatible.\r\n",
      "allennlp 2.10.1 requires transformers<4.21,>=4.1, but you have transformers 4.27.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed diffusers-0.14.0 huggingface-hub-0.13.3 transformers-4.27.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets accelerate wandb open-clip-torch\n",
    "!pip install --upgrade diffusers scipy transformers\n",
    "#!pip install -qq diffusers transformers datasets accelerate wandb open-clip-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d016d50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T16:39:31.730617Z",
     "iopub.status.busy": "2023-03-25T16:39:31.730245Z",
     "iopub.status.idle": "2023-03-25T16:39:33.265831Z",
     "shell.execute_reply": "2023-03-25T16:39:33.263153Z"
    },
    "papermill": {
     "duration": 1.545107,
     "end_time": "2023-03-25T16:39:33.269591",
     "exception": false,
     "start_time": "2023-03-25T16:39:31.724484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb_api = '7bc198602eed746dfff8b8b8b95c1a80df1cf705'\n",
    "wandb.login(key=wandb_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f604e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T16:39:33.300694Z",
     "iopub.status.busy": "2023-03-25T16:39:33.300357Z",
     "iopub.status.idle": "2023-03-25T16:39:44.708683Z",
     "shell.execute_reply": "2023-03-25T16:39:44.707381Z"
    },
    "papermill": {
     "duration": 11.424996,
     "end_time": "2023-03-25T16:39:44.711355",
     "exception": false,
     "start_time": "2023-03-25T16:39:33.286359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub==0.10\r\n",
      "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub==0.10) (6.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface_hub==0.10) (4.64.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub==0.10) (4.1.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface_hub==0.10) (3.7.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub==0.10) (23.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface_hub==0.10) (2.28.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface_hub==0.10) (6.0.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface_hub==0.10) (3.8.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub==0.10) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub==0.10) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub==0.10) (2.1.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub==0.10) (1.26.14)\r\n",
      "Installing collected packages: huggingface_hub\r\n",
      "  Attempting uninstall: huggingface_hub\r\n",
      "    Found existing installation: huggingface-hub 0.13.3\r\n",
      "    Uninstalling huggingface-hub-0.13.3:\r\n",
      "      Successfully uninstalled huggingface-hub-0.13.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "transformers 4.27.3 requires huggingface-hub<1.0,>=0.11.0, but you have huggingface-hub 0.10.0 which is incompatible.\r\n",
      "allennlp 2.10.1 requires transformers<4.21,>=4.1, but you have transformers 4.27.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed huggingface_hub-0.10.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub==0.10\n",
    "#!pip install --upgrade huggingface_hub\n",
    "\n",
    "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ca77e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T16:39:44.724008Z",
     "iopub.status.busy": "2023-03-25T16:39:44.723676Z",
     "iopub.status.idle": "2023-03-25T16:39:46.087214Z",
     "shell.execute_reply": "2023-03-25T16:39:46.086048Z"
    },
    "papermill": {
     "duration": 1.372752,
     "end_time": "2023-03-25T16:39:46.089756",
     "exception": false,
     "start_time": "2023-03-25T16:39:44.717004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-25 16:39:45--  https://github.com/DiningSystem/diffusion-models-class/raw/main/unit2/finetune_model.py\r\n",
      "Resolving github.com (github.com)... 140.82.113.3\r\n",
      "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://raw.githubusercontent.com/DiningSystem/diffusion-models-class/main/unit2/finetune_model.py [following]\r\n",
      "--2023-03-25 16:39:45--  https://raw.githubusercontent.com/DiningSystem/diffusion-models-class/main/unit2/finetune_model.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 5481 (5.4K) [text/plain]\r\n",
      "Saving to: ‘finetune_model.py’\r\n",
      "\r\n",
      "finetune_model.py   100%[===================>]   5.35K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2023-03-25 16:39:45 (51.2 MB/s) - ‘finetune_model.py’ saved [5481/5481]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DiningSystem/diffusion-models-class/raw/main/unit2/finetune_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5af0d5b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T16:39:46.103503Z",
     "iopub.status.busy": "2023-03-25T16:39:46.102842Z",
     "iopub.status.idle": "2023-03-25T16:39:46.107555Z",
     "shell.execute_reply": "2023-03-25T16:39:46.106346Z"
    },
    "papermill": {
     "duration": 0.01401,
     "end_time": "2023-03-25T16:39:46.109871",
     "exception": false,
     "start_time": "2023-03-25T16:39:46.095861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export CUDA_VISIBLE_DEVICES=0,1\n",
    "#from accelerate import Accelerator\n",
    "#accelerator = Accelerator()\n",
    "#print(accelerator.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae4d9743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T16:39:46.123063Z",
     "iopub.status.busy": "2023-03-25T16:39:46.122248Z",
     "iopub.status.idle": "2023-03-25T16:39:46.126568Z",
     "shell.execute_reply": "2023-03-25T16:39:46.125507Z"
    },
    "papermill": {
     "duration": 0.012856,
     "end_time": "2023-03-25T16:39:46.128648",
     "exception": false,
     "start_time": "2023-03-25T16:39:46.115792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install onnxruntime-gpu\n",
    "#!pip install onnxruntime.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "315b3e6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T16:39:46.140912Z",
     "iopub.status.busy": "2023-03-25T16:39:46.140647Z",
     "iopub.status.idle": "2023-03-25T16:41:56.960131Z",
     "shell.execute_reply": "2023-03-25T16:41:56.958924Z"
    },
    "papermill": {
     "duration": 130.828556,
     "end_time": "2023-03-25T16:41:56.962928",
     "exception": false,
     "start_time": "2023-03-25T16:39:46.134372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\r\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\r\n",
      "0it [00:00, ?it/s]\r\n",
      "0it [00:00, ?it/s]\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhkhoinguyendo1210\u001b[0m (\u001b[33mgenerativemed\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhkhoinguyendo1210\u001b[0m (\u001b[33mgenerativemed\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.14.0 is available!  To upgrade, please run:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230325_164008-2qrmfiwg\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33methereal-morning-90\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/2qrmfiwg\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.14.0 is available!  To upgrade, please run:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230325_164008-cjquwgk1\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlight-bee-91\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/cjquwgk1\u001b[0m\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss ▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.00028\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss ▁\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.00268\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlight-bee-91\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/cjquwgk1\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230325_164008-cjquwgk1/logs\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33methereal-morning-90\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/2qrmfiwg\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230325_164008-2qrmfiwg/logs\u001b[0m\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/bin/torchrun\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\r\n",
      "    return f(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/run.py\", line 724, in main\r\n",
      "    run(args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/run.py\", line 718, in run\r\n",
      "    )(*cmd_args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launcher/api.py\", line 247, in launch_agent\r\n",
      "    failures=result.failures,\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "finetune_model.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2023-03-25_16:41:56\r\n",
      "  host      : 4a99a418493b\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 142)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2023-03-25_16:41:56\r\n",
      "  host      : 4a99a418493b\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 141)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/accelerate/commands/accelerate_cli.py\", line 43, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/accelerate/commands/launch.py\", line 831, in launch_command\r\n",
      "    multi_gpu_launcher(args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/accelerate/commands/launch.py\", line 450, in multi_gpu_launcher\r\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\n",
      "subprocess.CalledProcessError: Command '['torchrun', '--nproc_per_node', '2', 'finetune_model.py', '--image_size', '256', '--batch_size', '4', '--num_epochs', '100', '--grad_accumulation_steps', '4', '--start_model', 'DiningSystem/xray_diffuser', '--dataset_name', '/kaggle/input/xray2data/test_data_xray2/00001', '--wandb_project', 'dm-finetune', '--log_samples_every', '20', '--save_model_every', '1', '--model_save_name', 'xray_diffuser']' returned non-zero exit status 1.\r\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --multi_gpu --num_processes=2 finetune_model.py --image_size 256 --batch_size 4 --num_epochs 100\\\n",
    "     --grad_accumulation_steps 4 --start_model \"DiningSystem/xray_diffuser\"\\\n",
    "     --dataset_name \"/kaggle/input/xray2data/test_data_xray2/00001\" --wandb_project 'dm-finetune'\\\n",
    "     --log_samples_every 20 --save_model_every 1 --model_save_name \"xray_diffuser\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 197.187645,
   "end_time": "2023-03-25T16:41:57.505455",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-25T16:38:40.317810",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
