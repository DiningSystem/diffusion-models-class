{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "644a7453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T04:21:51.058296Z",
     "iopub.status.busy": "2023-03-25T04:21:51.057724Z",
     "iopub.status.idle": "2023-03-25T04:22:03.309088Z",
     "shell.execute_reply": "2023-03-25T04:22:03.307442Z"
    },
    "papermill": {
     "duration": 12.258686,
     "end_time": "2023-03-25T04:22:03.312058",
     "exception": false,
     "start_time": "2023-03-25T04:21:51.053372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install datasets accelerate wandb open-clip-torch\n",
    "#!pip install --upgrade diffusers scipy transformers\n",
    "!pip install -qq diffusers transformers datasets accelerate wandb open-clip-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15909c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T04:22:03.318037Z",
     "iopub.status.busy": "2023-03-25T04:22:03.317662Z",
     "iopub.status.idle": "2023-03-25T04:22:05.873718Z",
     "shell.execute_reply": "2023-03-25T04:22:05.872596Z"
    },
    "papermill": {
     "duration": 2.561895,
     "end_time": "2023-03-25T04:22:05.876313",
     "exception": false,
     "start_time": "2023-03-25T04:22:03.314418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb_api = '7bc198602eed746dfff8b8b8b95c1a80df1cf705'\n",
    "wandb.login(key=wandb_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c6ec77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T04:22:05.882574Z",
     "iopub.status.busy": "2023-03-25T04:22:05.882239Z",
     "iopub.status.idle": "2023-03-25T04:22:17.691338Z",
     "shell.execute_reply": "2023-03-25T04:22:17.689840Z"
    },
    "papermill": {
     "duration": 11.81529,
     "end_time": "2023-03-25T04:22:17.694025",
     "exception": false,
     "start_time": "2023-03-25T04:22:05.878735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.7/site-packages (0.12.1)\r\n",
      "Collecting huggingface_hub\r\n",
      "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.11.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (3.9.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (2.28.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.4.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (23.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.64.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface_hub) (3.11.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2.1.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (1.26.14)\r\n",
      "Installing collected packages: huggingface_hub\r\n",
      "  Attempting uninstall: huggingface_hub\r\n",
      "    Found existing installation: huggingface-hub 0.12.1\r\n",
      "    Uninstalling huggingface-hub-0.12.1:\r\n",
      "      Successfully uninstalled huggingface-hub-0.12.1\r\n",
      "Successfully installed huggingface_hub-0.13.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install huggingface_hub==0.10\n",
    "!pip install --upgrade huggingface_hub\n",
    "\n",
    "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825c9552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T04:22:17.702428Z",
     "iopub.status.busy": "2023-03-25T04:22:17.701446Z",
     "iopub.status.idle": "2023-03-25T04:22:18.980041Z",
     "shell.execute_reply": "2023-03-25T04:22:18.978844Z"
    },
    "papermill": {
     "duration": 1.285198,
     "end_time": "2023-03-25T04:22:18.982464",
     "exception": false,
     "start_time": "2023-03-25T04:22:17.697266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-25 04:22:18--  https://github.com/DiningSystem/diffusion-models-class/raw/main/unit2/finetune_model.py\r\n",
      "Resolving github.com (github.com)... 140.82.112.3\r\n",
      "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://raw.githubusercontent.com/DiningSystem/diffusion-models-class/main/unit2/finetune_model.py [following]\r\n",
      "--2023-03-25 04:22:18--  https://raw.githubusercontent.com/DiningSystem/diffusion-models-class/main/unit2/finetune_model.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 5481 (5.4K) [text/plain]\r\n",
      "Saving to: ‚Äòfinetune_model.py‚Äô\r\n",
      "\r\n",
      "finetune_model.py   100%[===================>]   5.35K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2023-03-25 04:22:18 (51.5 MB/s) - ‚Äòfinetune_model.py‚Äô saved [5481/5481]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DiningSystem/diffusion-models-class/raw/main/unit2/finetune_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "066872c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T04:22:18.991362Z",
     "iopub.status.busy": "2023-03-25T04:22:18.990306Z",
     "iopub.status.idle": "2023-03-25T04:22:21.857991Z",
     "shell.execute_reply": "2023-03-25T04:22:21.856507Z"
    },
    "papermill": {
     "duration": 2.875418,
     "end_time": "2023-03-25T04:22:21.861119",
     "exception": false,
     "start_time": "2023-03-25T04:22:18.985701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#export CUDA_VISIBLE_DEVICES=0,1\n",
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "print(accelerator.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d69722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T04:22:21.870172Z",
     "iopub.status.busy": "2023-03-25T04:22:21.869166Z",
     "iopub.status.idle": "2023-03-25T04:23:12.398028Z",
     "shell.execute_reply": "2023-03-25T04:23:12.396746Z"
    },
    "papermill": {
     "duration": 50.535918,
     "end_time": "2023-03-25T04:23:12.400789",
     "exception": false,
     "start_time": "2023-03-25T04:22:21.864871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime-gpu\r\n",
      "  Downloading onnxruntime_gpu-1.14.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136.2 MB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m136.2/136.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.7/site-packages (from onnxruntime-gpu) (1.21.6)\r\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.7/site-packages (from onnxruntime-gpu) (23.1.21)\r\n",
      "Collecting coloredlogs\r\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: sympy in /opt/conda/lib/python3.7/site-packages (from onnxruntime-gpu) (1.10.1)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from onnxruntime-gpu) (23.0)\r\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from onnxruntime-gpu) (3.20.3)\r\n",
      "Collecting humanfriendly>=9.1\r\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.7/site-packages (from sympy->onnxruntime-gpu) (1.2.1)\r\n",
      "Installing collected packages: humanfriendly, coloredlogs, onnxruntime-gpu\r\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.14.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting onnxruntime.training\r\n",
      "  Downloading onnxruntime_training-1.14.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (214.8 MB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m214.8/214.8 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: onnx in /opt/conda/lib/python3.7/site-packages (from onnxruntime.training) (1.13.1)\r\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from onnxruntime.training) (3.20.3)\r\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.7/site-packages (from onnxruntime.training) (23.1.21)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from onnxruntime.training) (3.8.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.7/site-packages (from onnxruntime.training) (1.10.1)\r\n",
      "Requirement already satisfied: setuptools>=41.4.0 in /opt/conda/lib/python3.7/site-packages (from onnxruntime.training) (59.8.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from onnxruntime.training) (23.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from onnxruntime.training) (1.21.6)\r\n",
      "Collecting cerberus\r\n",
      "  Downloading Cerberus-1.3.4.tar.gz (63 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.7/site-packages (from onnx->onnxruntime.training) (4.4.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.7/site-packages (from sympy->onnxruntime.training) (1.2.1)\r\n",
      "Building wheels for collected packages: cerberus\r\n",
      "  Building wheel for cerberus (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for cerberus: filename=Cerberus-1.3.4-py3-none-any.whl size=58193 sha256=a1091fbc946f45e68b8de28fcf96f89cac314e42f50fa90c0edaf5bbf1f62b2c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/7a/93/69/463dbbac15e3c79384c92ec13f75d46b3e27034e2f764d9f85\r\n",
      "Successfully built cerberus\r\n",
      "Installing collected packages: cerberus, onnxruntime.training\r\n",
      "Successfully installed cerberus-1.3.4 onnxruntime.training-1.14.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime-gpu\n",
    "!pip install onnxruntime.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f41dd6fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T04:23:12.422242Z",
     "iopub.status.busy": "2023-03-25T04:23:12.421687Z",
     "iopub.status.idle": "2023-03-25T04:25:23.792077Z",
     "shell.execute_reply": "2023-03-25T04:25:23.790534Z"
    },
    "papermill": {
     "duration": 131.38432,
     "end_time": "2023-03-25T04:25:23.795141",
     "exception": false,
     "start_time": "2023-03-25T04:23:12.410821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\r\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\r\n",
      "Moving 0 files to the new cache system\r\n",
      "Moving 0 files to the new cache system\r\n",
      "0it [00:00, ?it/s]\r\n",
      "\r\n",
      "/opt/conda/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_validation.py:114: UserWarning: WARNING: failed to get cudart_version from onnxruntime build info.\r\n",
      "  warnings.warn(\"WARNING: failed to get cudart_version from onnxruntime build info.\")\r\n",
      "/opt/conda/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_validation.py:114: UserWarning: WARNING: failed to get cudart_version from onnxruntime build info.\r\n",
      "  warnings.warn(\"WARNING: failed to get cudart_version from onnxruntime build info.\")\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhkhoinguyendo1210\u001b[0m (\u001b[33mgenerativemed\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhkhoinguyendo1210\u001b[0m (\u001b[33mgenerativemed\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.14.0 is available!  To upgrade, please run:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.10\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230325_042340-qt19s2qp\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcopper-cherry-79\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/qt19s2qp\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.14.0 is available!  To upgrade, please run:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.10\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230325_042340-pcknjwvb\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdry-glitter-80\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/pcknjwvb\u001b[0m\r\n",
      "Downloading (‚Ä¶)on_pytorch_model.bin: 100%|‚ñà‚ñà‚ñà| 455M/455M [00:10<00:00, 45.1MB/s]\r\n",
      "Downloading (‚Ä¶)lve/main/config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 998/998 [00:00<00:00, 42.5kB/s]\r\n",
      "Downloading (‚Ä¶)cheduler_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [00:00<00:00, 15.5kB/s]\r\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 19945.71it/s]\r\n",
      "Resolving data files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 99919.10it/s]\r\n",
      "Downloading and preparing dataset image_folder/00001 to /root/.cache/huggingface/datasets/image_folder/00001-528e12b165c5b660/0.0.0/ee92df8e96c6907f3c851a987be3fd03d4b93b247e727b69a8e23ac94392a091...\r\n",
      "Downloading data files #0:   0%|                        | 0/63 [00:00<?, ?obj/s]\r\n",
      "Downloading data files #1:   0%|                        | 0/63 [00:00<?, ?obj/s]\u001b[A\r\n",
      "\r\n",
      "Downloading data files #2:   0%|                        | 0/63 [00:00<?, ?obj/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "Downloading data files #3:   0%|                        | 0/63 [00:00<?, ?obj/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading data files #4:   0%|                        | 0/63 [00:00<?, ?obj/s]\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading data files #6:   0%|                        | 0/63 [00:00<?, ?obj/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading data files #5:   0%|                        | 0/63 [00:00<?, ?obj/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading data files #3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 3273.88obj/s]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading data files #0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 896.99obj/s]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading data files #10:   0%|                       | 0/62 [00:00<?, ?obj/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading data files #9:   0%|                        | 0/62 [00:00<?, ?obj/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading data files #5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 1465.55obj/s]\r\n",
      "Downloading data files #7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 1628.39obj/s]\r\n",
      "Downloading data files #1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 733.95obj/s]\r\n",
      "Downloading data files #11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [00:00<00:00, 3673.81obj/s]\r\n",
      "Downloading data files #10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [00:00<00:00, 2836.86obj/s]\r\n",
      "Downloading data files #9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [00:00<00:00, 2786.79obj/s]\r\n",
      "Downloading data files #6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 1097.20obj/s]\r\n",
      "Downloading data files #2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 689.44obj/s]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading data files #12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [00:00<00:00, 15908.90obj/s]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading data files #15:   0%|                       | 0/62 [00:00<?, ?obj/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading data files #14:   0%|                       | 0/62 [00:00<?, ?obj/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading data files #8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [00:00<00:00, 1009.92obj/s]\r\n",
      "Downloading data files #4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:00<00:00, 612.40obj/s]\r\n",
      "Downloading data files #15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [00:00<00:00, 2218.47obj/s]\r\n",
      "Downloading data files #13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [00:00<00:00, 2564.11obj/s]\r\n",
      "Downloading data files #14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [00:00<00:00, 1974.31obj/s]\r\n",
      "Downloading data files: 0it [00:00, ?it/s]\r\n",
      "Extracting data files: 0it [00:00, ?it/s]\r\n",
      "Dataset image_folder downloaded and prepared to /root/.cache/huggingface/datasets/image_folder/00001-528e12b165c5b660/0.0.0/ee92df8e96c6907f3c851a987be3fd03d4b93b247e727b69a8e23ac94392a091. Subsequent calls will reuse this data.\r\n",
      "  0%|                                                   | 0/125 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py:199: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\r\n",
      "grad.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]\r\n",
      "bucket_view.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at /usr/local/src/pytorch/torch/csrc/distributed/c10d/reducer.cpp:325.)\r\n",
      "  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\r\n",
      "  0%|                                                   | 0/125 [00:06<?, ?it/s]\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"finetune_model.py\", line 26, in <module>\r\n",
      "    save_model_every = 2500,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/fastcore/script.py\", line 125, in call_parse\r\n",
      "/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py:199: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\r\n",
      "grad.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1024, 1024]\r\n",
      "bucket_view.sizes() = [512, 1024, 1, 1], strides() = [1024, 1, 1, 1] (Triggered internally at /usr/local/src/pytorch/torch/csrc/distributed/c10d/reducer.cpp:325.)\r\n",
      "  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\r\n",
      "    return _f()\r\n",
      "  0%|                                                   | 0/125 [00:06<?, ?it/s]\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/fastcore/script.py\", line 119, in _f\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"finetune_model.py\", line 26, in <module>\r\n",
      "        save_model_every = 2500,return tfunc(**merge(args, args_from_prog(func, xtra)))\r\n",
      "  File \"finetune_model.py\", line 121, in train\r\n",
      "    image_pipe.save_pretrained(model_save_name+f'step_{step+1}')\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/diffusers/pipelines/pipeline_utils.py\", line 330, in save_pretrained\r\n",
      "\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/fastcore/script.py\", line 125, in call_parse\r\n",
      "    return _f()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/fastcore/script.py\", line 119, in _f\r\n",
      "    return tfunc(**merge(args, args_from_prog(func, xtra)))\r\n",
      "  File \"finetune_model.py\", line 121, in train\r\n",
      "    image_pipe.save_pretrained(model_save_name+f'step_{step+1}')\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/diffusers/pipelines/pipeline_utils.py\", line 330, in save_pretrained\r\n",
      "        save_method = getattr(sub_model, save_method_name)\r\n",
      "save_method = getattr(sub_model, save_method_name)\r\n",
      "TypeError: TypeErrorgetattr(): attribute name must be string: \r\n",
      "getattr(): attribute name must be string\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/bin/torchrun\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\r\n",
      "    return f(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/run.py\", line 762, in main\r\n",
      "    run(args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/run.py\", line 756, in run\r\n",
      "    )(*cmd_args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launcher/api.py\", line 132, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launcher/api.py\", line 248, in launch_agent\r\n",
      "    failures=result.failures,\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "finetune_model.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2023-03-25_04:25:23\r\n",
      "  host      : 9348187003db\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 178)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2023-03-25_04:25:23\r\n",
      "  host      : 9348187003db\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 177)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/accelerate/commands/accelerate_cli.py\", line 43, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/accelerate/commands/launch.py\", line 831, in launch_command\r\n",
      "    multi_gpu_launcher(args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/accelerate/commands/launch.py\", line 450, in multi_gpu_launcher\r\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\n",
      "subprocess.CalledProcessError: Command '['torchrun', '--nproc_per_node', '2', 'finetune_model.py', '--image_size', '256', '--batch_size', '4', '--num_epochs', '100', '--grad_accumulation_steps', '8', '--start_model', 'DiningSystem/xray_diffuser', '--dataset_name', '/kaggle/input/xray2data/test_data_xray2/00001', '--wandb_project', 'dm-finetune', '--log_samples_every', '20', '--save_model_every', '1', '--model_save_name', 'xray_diffuser']' returned non-zero exit status 1.\r\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --multi_gpu --num_processes=2 finetune_model.py --image_size 256 --batch_size 4 --num_epochs 100\\\n",
    "     --grad_accumulation_steps 8 --start_model \"DiningSystem/xray_diffuser\"\\\n",
    "     --dataset_name \"/kaggle/input/xray2data/test_data_xray2/00001\" --wandb_project 'dm-finetune'\\\n",
    "     --log_samples_every 20 --save_model_every 1 --model_save_name \"xray_diffuser\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 224.735155,
   "end_time": "2023-03-25T04:25:26.431689",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-25T04:21:41.696534",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
