{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb76bc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T20:41:46.655626Z",
     "iopub.status.busy": "2023-02-11T20:41:46.655083Z",
     "iopub.status.idle": "2023-02-11T20:42:05.569092Z",
     "shell.execute_reply": "2023-02-11T20:42:05.567901Z"
    },
    "papermill": {
     "duration": 18.920986,
     "end_time": "2023-02-11T20:42:05.571796",
     "exception": false,
     "start_time": "2023-02-11T20:41:46.650810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\r\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "tfx-bsl 1.9.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.52.0 which is incompatible.\r\n",
      "tfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires h5py~=3.1.0, but you have h5py 3.8.0 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires typing-extensions<3.11,>=3.7, but you have typing-extensions 4.1.1 which is incompatible.\r\n",
      "tensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "tensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "tensorboardx 2.5.1 requires protobuf<=3.20.1,>=3.8.0, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ortools 9.5.2237 requires protobuf>=4.21.5, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "onnx 1.12.0 requires protobuf<=3.20.1,>=3.12.2, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "nnabla 1.33.0 requires protobuf<=3.19.4; platform_system != \"Windows\", but you have protobuf 3.20.3 which is incompatible.\r\n",
      "gcsfs 2022.5.0 requires fsspec==2022.5.0, but you have fsspec 2023.1.0 which is incompatible.\r\n",
      "apache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qq diffusers[\"torch\"] datasets accelerate wandb open-clip-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b8b546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T20:42:05.577067Z",
     "iopub.status.busy": "2023-02-11T20:42:05.576759Z",
     "iopub.status.idle": "2023-02-11T20:42:07.786645Z",
     "shell.execute_reply": "2023-02-11T20:42:07.785657Z"
    },
    "papermill": {
     "duration": 2.215453,
     "end_time": "2023-02-11T20:42:07.789299",
     "exception": false,
     "start_time": "2023-02-11T20:42:05.573846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb_api = '7bc198602eed746dfff8b8b8b95c1a80df1cf705'\n",
    "wandb.login(key=wandb_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a622849d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T20:42:07.795940Z",
     "iopub.status.busy": "2023-02-11T20:42:07.794868Z",
     "iopub.status.idle": "2023-02-11T20:42:09.672503Z",
     "shell.execute_reply": "2023-02-11T20:42:09.671357Z"
    },
    "papermill": {
     "duration": 1.883331,
     "end_time": "2023-02-11T20:42:09.674879",
     "exception": false,
     "start_time": "2023-02-11T20:42:07.791548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-11 20:42:08--  https://github.com/DiningSystem/diffusion-models-class/raw/main/unit2/finetune_model.py\r\n",
      "Resolving github.com (github.com)... 140.82.114.4\r\n",
      "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://raw.githubusercontent.com/DiningSystem/diffusion-models-class/main/unit2/finetune_model.py [following]\r\n",
      "--2023-02-11 20:42:09--  https://raw.githubusercontent.com/DiningSystem/diffusion-models-class/main/unit2/finetune_model.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 4617 (4.5K) [text/plain]\r\n",
      "Saving to: ‚Äòfinetune_model.py‚Äô\r\n",
      "\r\n",
      "finetune_model.py   100%[===================>]   4.51K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2023-02-11 20:42:09 (38.7 MB/s) - ‚Äòfinetune_model.py‚Äô saved [4617/4617]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DiningSystem/diffusion-models-class/raw/main/unit2/finetune_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28faab87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T20:42:09.681394Z",
     "iopub.status.busy": "2023-02-11T20:42:09.681038Z",
     "iopub.status.idle": "2023-02-11T20:43:12.698793Z",
     "shell.execute_reply": "2023-02-11T20:43:12.697575Z"
    },
    "papermill": {
     "duration": 63.02397,
     "end_time": "2023-02-11T20:43:12.701338",
     "exception": false,
     "start_time": "2023-02-11T20:42:09.677368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhkhoinguyendo1210\u001b[0m (\u001b[33mgenerativemed\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.10 is available!  To upgrade, please run:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230211_204219-22eoe17u\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlaced-eon-11\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/22eoe17u\u001b[0m\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlaced-eon-11\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/22eoe17u\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230211_204219-22eoe17u/logs\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python finetune_model.py --image_size 256 --batch_size 4 --num_epochs 100\\\n",
    "     --grad_accumulation_steps 4 --start_model \"DiningSystem/xray_diffuser\"\\\n",
    "     --dataset_name \"/kaggle/input/xray2data/test_data_xray2/00001\" --wandb_project 'dm-finetune'\\\n",
    "     --log_samples_every 100 --save_model_every 100 --model_save_name 'xray_diffuser'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 94.735934,
   "end_time": "2023-02-11T20:43:13.234359",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-11T20:41:38.498425",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
