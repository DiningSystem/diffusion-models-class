{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec1e67a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T03:20:16.303812Z",
     "iopub.status.busy": "2023-03-24T03:20:16.303027Z",
     "iopub.status.idle": "2023-03-24T03:20:47.637209Z",
     "shell.execute_reply": "2023-03-24T03:20:47.636038Z"
    },
    "papermill": {
     "duration": 31.341615,
     "end_time": "2023-03-24T03:20:47.640194",
     "exception": false,
     "start_time": "2023-03-24T03:20:16.298579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in /opt/conda/lib/python3.7/site-packages (0.14.0)\r\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (1.7.3)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from diffusers) (6.0.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from diffusers) (3.7.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from diffusers) (0.10.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from diffusers) (1.21.6)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from diffusers) (2.28.1)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from diffusers) (9.1.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from diffusers) (2021.11.10)\r\n",
      "Collecting huggingface-hub>=0.10.0\r\n",
      "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\r\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.10.0->diffusers) (4.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->diffusers) (3.8.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (2022.12.7)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (2.1.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (1.26.14)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (3.3)\r\n",
      "Installing collected packages: huggingface-hub, transformers\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.10.1\r\n",
      "    Uninstalling huggingface-hub-0.10.1:\r\n",
      "      Successfully uninstalled huggingface-hub-0.10.1\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.20.1\r\n",
      "    Uninstalling transformers-4.20.1:\r\n",
      "      Successfully uninstalled transformers-4.20.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cached-path 1.1.6 requires huggingface-hub<0.11.0,>=0.8.1, but you have huggingface-hub 0.13.3 which is incompatible.\r\n",
      "allennlp 2.10.1 requires transformers<4.21,>=4.1, but you have transformers 4.27.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.13.3 transformers-4.27.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qq diffusers datasets accelerate wandb open-clip-torch\n",
    "!pip install --upgrade diffusers transformers scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ceb0506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T03:20:47.648105Z",
     "iopub.status.busy": "2023-03-24T03:20:47.647791Z",
     "iopub.status.idle": "2023-03-24T03:20:49.037194Z",
     "shell.execute_reply": "2023-03-24T03:20:49.036174Z"
    },
    "papermill": {
     "duration": 1.39554,
     "end_time": "2023-03-24T03:20:49.039240",
     "exception": false,
     "start_time": "2023-03-24T03:20:47.643700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb_api = '7bc198602eed746dfff8b8b8b95c1a80df1cf705'\n",
    "wandb.login(key=wandb_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79a7cb36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T03:20:49.047213Z",
     "iopub.status.busy": "2023-03-24T03:20:49.046897Z",
     "iopub.status.idle": "2023-03-24T03:21:00.138996Z",
     "shell.execute_reply": "2023-03-24T03:21:00.137646Z"
    },
    "papermill": {
     "duration": 11.099095,
     "end_time": "2023-03-24T03:21:00.141824",
     "exception": false,
     "start_time": "2023-03-24T03:20:49.042729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.7/site-packages (0.13.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.64.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (6.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (23.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (6.0.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (3.7.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (2.28.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface_hub) (3.8.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (1.26.14)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2.1.0)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install huggingface_hub==0.10\n",
    "!pip install --upgrade huggingface_hub\n",
    "\n",
    "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7134ab2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T03:21:00.150961Z",
     "iopub.status.busy": "2023-03-24T03:21:00.150044Z",
     "iopub.status.idle": "2023-03-24T03:21:01.739600Z",
     "shell.execute_reply": "2023-03-24T03:21:01.738268Z"
    },
    "papermill": {
     "duration": 1.596856,
     "end_time": "2023-03-24T03:21:01.742336",
     "exception": false,
     "start_time": "2023-03-24T03:21:00.145480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-24 03:21:01--  https://github.com/DiningSystem/diffusion-models-class/raw/main/unit2/finetune_model.py\r\n",
      "Resolving github.com (github.com)... 140.82.113.3\r\n",
      "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://raw.githubusercontent.com/DiningSystem/diffusion-models-class/main/unit2/finetune_model.py [following]\r\n",
      "--2023-03-24 03:21:01--  https://raw.githubusercontent.com/DiningSystem/diffusion-models-class/main/unit2/finetune_model.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 5305 (5.2K) [text/plain]\r\n",
      "Saving to: ‚Äòfinetune_model.py‚Äô\r\n",
      "\r\n",
      "finetune_model.py   100%[===================>]   5.18K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2023-03-24 03:21:01 (46.4 MB/s) - ‚Äòfinetune_model.py‚Äô saved [5305/5305]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DiningSystem/diffusion-models-class/raw/main/unit2/finetune_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be61fc88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T03:21:01.751704Z",
     "iopub.status.busy": "2023-03-24T03:21:01.751334Z",
     "iopub.status.idle": "2023-03-24T03:21:04.154073Z",
     "shell.execute_reply": "2023-03-24T03:21:04.152512Z"
    },
    "papermill": {
     "duration": 2.41005,
     "end_time": "2023-03-24T03:21:04.156342",
     "exception": false,
     "start_time": "2023-03-24T03:21:01.746292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#export CUDA_VISIBLE_DEVICES=0,1\n",
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "print(accelerator.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a11a1af7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-24T03:21:04.165932Z",
     "iopub.status.busy": "2023-03-24T03:21:04.165329Z",
     "iopub.status.idle": "2023-03-24T03:23:08.915748Z",
     "shell.execute_reply": "2023-03-24T03:23:08.914524Z"
    },
    "papermill": {
     "duration": 124.757857,
     "end_time": "2023-03-24T03:23:08.918289",
     "exception": false,
     "start_time": "2023-03-24T03:21:04.160432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\r\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\r\n",
      "0it [00:00, ?it/s]\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhkhoinguyendo1210\u001b[0m (\u001b[33mgenerativemed\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhkhoinguyendo1210\u001b[0m (\u001b[33mgenerativemed\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.14.0 is available!  To upgrade, please run:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230324_032124-3bfrvowp\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mapricot-voice-51\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/3bfrvowp\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.14.0 is available!  To upgrade, please run:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230324_032124-3ej19dr6\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msolar-galaxy-52\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/3ej19dr6\u001b[0m\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mapricot-voice-51\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/3bfrvowp\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230324_032124-3bfrvowp/logs\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msolar-galaxy-52\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/3ej19dr6\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230324_032124-3ej19dr6/logs\u001b[0m\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/bin/torchrun\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\r\n",
      "    return f(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/run.py\", line 724, in main\r\n",
      "    run(args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/run.py\", line 718, in run\r\n",
      "    )(*cmd_args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launcher/api.py\", line 247, in launch_agent\r\n",
      "    failures=result.failures,\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "finetune_model.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2023-03-24_03:23:08\r\n",
      "  host      : e8e48ab69880\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 119)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2023-03-24_03:23:08\r\n",
      "  host      : e8e48ab69880\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 118)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/accelerate/commands/accelerate_cli.py\", line 43, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/accelerate/commands/launch.py\", line 831, in launch_command\r\n",
      "    multi_gpu_launcher(args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/accelerate/commands/launch.py\", line 450, in multi_gpu_launcher\r\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\n",
      "subprocess.CalledProcessError: Command '['torchrun', '--nproc_per_node', '2', 'finetune_model.py', '--image_size', '256', '--batch_size', '1', '--num_epochs', '10', '--grad_accumulation_steps', '2', '--start_model', 'CompVis/ldm-celebahq-256', '--dataset_name', '/kaggle/input/xray2data/test_data_xray2/00001', '--wandb_project', 'dm-finetune', '--log_samples_every', '5', '--save_model_every', '5', '--model_save_name', 'xray_diffuser']' returned non-zero exit status 1.\r\n"
     ]
    }
   ],
   "source": [
    "!PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb accelerate launch --multi_gpu --mixed_precision=fp16 --num_processes=2 finetune_model.py --image_size 256 --batch_size 1 --num_epochs 10\\\n",
    "     --grad_accumulation_steps 2 --start_model \"CompVis/ldm-celebahq-256\"\\\n",
    "     --dataset_name \"/kaggle/input/xray2data/test_data_xray2/00001\" --wandb_project 'dm-finetune'\\\n",
    "     --log_samples_every 5 --save_model_every 5 --model_save_name 'xray_diffuser' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 181.718293,
   "end_time": "2023-03-24T03:23:09.752401",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-24T03:20:08.034108",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
