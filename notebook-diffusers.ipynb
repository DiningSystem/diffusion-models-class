{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0f154f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T23:48:36.028383Z",
     "iopub.status.busy": "2023-03-23T23:48:36.027815Z",
     "iopub.status.idle": "2023-03-23T23:49:07.386402Z",
     "shell.execute_reply": "2023-03-23T23:49:07.385160Z"
    },
    "papermill": {
     "duration": 31.365712,
     "end_time": "2023-03-23T23:49:07.388972",
     "exception": false,
     "start_time": "2023-03-23T23:48:36.023260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in /opt/conda/lib/python3.7/site-packages (0.14.0)\r\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (1.7.3)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from diffusers) (9.1.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from diffusers) (1.21.6)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from diffusers) (2021.11.10)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from diffusers) (0.10.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from diffusers) (3.7.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from diffusers) (2.28.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from diffusers) (6.0.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\r\n",
      "Collecting huggingface-hub>=0.10.0\r\n",
      "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.10.0->diffusers) (4.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->diffusers) (3.8.0)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->diffusers) (1.26.14)\r\n",
      "Installing collected packages: huggingface-hub, transformers\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.10.1\r\n",
      "    Uninstalling huggingface-hub-0.10.1:\r\n",
      "      Successfully uninstalled huggingface-hub-0.10.1\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.20.1\r\n",
      "    Uninstalling transformers-4.20.1:\r\n",
      "      Successfully uninstalled transformers-4.20.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cached-path 1.1.6 requires huggingface-hub<0.11.0,>=0.8.1, but you have huggingface-hub 0.13.3 which is incompatible.\r\n",
      "allennlp 2.10.1 requires transformers<4.21,>=4.1, but you have transformers 4.27.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.13.3 transformers-4.27.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qq diffusers datasets accelerate wandb open-clip-torch\n",
    "!pip install --upgrade diffusers transformers scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c01eb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T23:49:07.396800Z",
     "iopub.status.busy": "2023-03-23T23:49:07.396501Z",
     "iopub.status.idle": "2023-03-23T23:49:08.802042Z",
     "shell.execute_reply": "2023-03-23T23:49:08.801056Z"
    },
    "papermill": {
     "duration": 1.412306,
     "end_time": "2023-03-23T23:49:08.804675",
     "exception": false,
     "start_time": "2023-03-23T23:49:07.392369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb_api = '7bc198602eed746dfff8b8b8b95c1a80df1cf705'\n",
    "wandb.login(key=wandb_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84732d45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T23:49:08.816177Z",
     "iopub.status.busy": "2023-03-23T23:49:08.815835Z",
     "iopub.status.idle": "2023-03-23T23:49:20.102604Z",
     "shell.execute_reply": "2023-03-23T23:49:20.100963Z"
    },
    "papermill": {
     "duration": 11.294884,
     "end_time": "2023-03-23T23:49:20.105114",
     "exception": false,
     "start_time": "2023-03-23T23:49:08.810230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.7/site-packages (0.13.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (2.28.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (23.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (6.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.64.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (3.7.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (6.0.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface_hub) (3.8.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (1.26.14)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2.1.0)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install huggingface_hub==0.10\n",
    "!pip install --upgrade huggingface_hub\n",
    "\n",
    "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5399c273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T23:49:20.114782Z",
     "iopub.status.busy": "2023-03-23T23:49:20.113875Z",
     "iopub.status.idle": "2023-03-23T23:49:21.521190Z",
     "shell.execute_reply": "2023-03-23T23:49:21.520091Z"
    },
    "papermill": {
     "duration": 1.414448,
     "end_time": "2023-03-23T23:49:21.523454",
     "exception": false,
     "start_time": "2023-03-23T23:49:20.109006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-23 23:49:21--  https://github.com/DiningSystem/diffusion-models-class/raw/main/unit2/finetune_model.py\r\n",
      "Resolving github.com (github.com)... 140.82.114.4\r\n",
      "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://raw.githubusercontent.com/DiningSystem/diffusion-models-class/main/unit2/finetune_model.py [following]\r\n",
      "--2023-03-23 23:49:21--  https://raw.githubusercontent.com/DiningSystem/diffusion-models-class/main/unit2/finetune_model.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 5199 (5.1K) [text/plain]\r\n",
      "Saving to: ‘finetune_model.py’\r\n",
      "\r\n",
      "finetune_model.py   100%[===================>]   5.08K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2023-03-23 23:49:21 (22.9 MB/s) - ‘finetune_model.py’ saved [5199/5199]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DiningSystem/diffusion-models-class/raw/main/unit2/finetune_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e80e46db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T23:49:21.533745Z",
     "iopub.status.busy": "2023-03-23T23:49:21.532745Z",
     "iopub.status.idle": "2023-03-23T23:49:21.537832Z",
     "shell.execute_reply": "2023-03-23T23:49:21.536945Z"
    },
    "papermill": {
     "duration": 0.012295,
     "end_time": "2023-03-23T23:49:21.539730",
     "exception": false,
     "start_time": "2023-03-23T23:49:21.527435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export CUDA_VISIBLE_DEVICES=0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0303e0c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T23:49:21.548611Z",
     "iopub.status.busy": "2023-03-23T23:49:21.548040Z",
     "iopub.status.idle": "2023-03-23T23:51:32.474878Z",
     "shell.execute_reply": "2023-03-23T23:51:32.473645Z"
    },
    "papermill": {
     "duration": 130.933984,
     "end_time": "2023-03-23T23:51:32.477465",
     "exception": false,
     "start_time": "2023-03-23T23:49:21.543481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\r\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\r\n",
      "0it [00:00, ?it/s]\r\n",
      "0it [00:00, ?it/s]\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhkhoinguyendo1210\u001b[0m (\u001b[33mgenerativemed\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhkhoinguyendo1210\u001b[0m (\u001b[33mgenerativemed\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.14.0 is available!  To upgrade, please run:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230323_234943-1rh3943s\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sky-37\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/1rh3943s\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.14.0 is available!  To upgrade, please run:\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230323_234943-30cy38e5\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlyric-gorge-37\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/30cy38e5\u001b[0m\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sky-37\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/1rh3943s\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230323_234943-1rh3943s/logs\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlyric-gorge-37\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/generativemed/dm-finetune/runs/30cy38e5\u001b[0m\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230323_234943-30cy38e5/logs\u001b[0m\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/bin/torchrun\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\r\n",
      "    return f(*args, **kwargs)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/run.py\", line 724, in main\r\n",
      "    run(args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/run.py\", line 718, in run\r\n",
      "    )(*cmd_args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\r\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/distributed/launcher/api.py\", line 247, in launch_agent\r\n",
      "    failures=result.failures,\r\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n",
      "============================================================\r\n",
      "finetune_model.py FAILED\r\n",
      "------------------------------------------------------------\r\n",
      "Failures:\r\n",
      "[1]:\r\n",
      "  time      : 2023-03-23_23:51:31\r\n",
      "  host      : f1b869fbde20\r\n",
      "  rank      : 1 (local_rank: 1)\r\n",
      "  exitcode  : 1 (pid: 118)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "------------------------------------------------------------\r\n",
      "Root Cause (first observed failure):\r\n",
      "[0]:\r\n",
      "  time      : 2023-03-23_23:51:31\r\n",
      "  host      : f1b869fbde20\r\n",
      "  rank      : 0 (local_rank: 0)\r\n",
      "  exitcode  : 1 (pid: 117)\r\n",
      "  error_file: <N/A>\r\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\r\n",
      "============================================================\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/opt/conda/bin/accelerate\", line 8, in <module>\r\n",
      "    sys.exit(main())\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/accelerate/commands/accelerate_cli.py\", line 43, in main\r\n",
      "    args.func(args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/accelerate/commands/launch.py\", line 831, in launch_command\r\n",
      "    multi_gpu_launcher(args)\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/accelerate/commands/launch.py\", line 450, in multi_gpu_launcher\r\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\n",
      "subprocess.CalledProcessError: Command '['torchrun', '--nproc_per_node', '2', 'finetune_model.py', '--image_size', '256', '--batch_size', '2', '--num_epochs', '10', '--grad_accumulation_steps', '2', '--start_model', 'CompVis/ldm-celebahq-256', '--dataset_name', '/kaggle/input/xray2data/test_data_xray2/00001', '--wandb_project', 'dm-finetune', '--log_samples_every', '100', '--save_model_every', '100', '--model_save_name', 'xray_diffuser']' returned non-zero exit status 1.\r\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1 accelerate launch --multi_gpu --mixed_precision=fp16 --num_processes=2 finetune_model.py --image_size 256 --batch_size 2 --num_epochs 10\\\n",
    "     --grad_accumulation_steps 2 --start_model \"CompVis/ldm-celebahq-256\"\\\n",
    "     --dataset_name \"/kaggle/input/xray2data/test_data_xray2/00001\" --wandb_project 'dm-finetune'\\\n",
    "     --log_samples_every 100 --save_model_every 100 --model_save_name 'xray_diffuser' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 185.956843,
   "end_time": "2023-03-23T23:51:33.011019",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-23T23:48:27.054176",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
